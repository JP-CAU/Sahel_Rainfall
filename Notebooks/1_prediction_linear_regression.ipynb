{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import darts\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jake/desktop/git/Sahel_Rainfall/.ve_Sahel_Rainfall/lib/python3.10/site-packages/numpy/core/fromnumeric.py:3462: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
      "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n",
      "/home/jake/desktop/git/Sahel_Rainfall/.ve_Sahel_Rainfall/lib/python3.10/site-packages/numpy/core/fromnumeric.py:3462: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
      "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Set url:\n",
    "data_url = (\n",
    "    \"https://github.com/MarcoLandtHayen/climate_index_collection/\"\n",
    "    \"releases/download/v2023.03.29.1/climate_indices.csv\"\n",
    ")\n",
    "\n",
    "# Load data:\n",
    "climind = pd.read_csv(data_url)\n",
    "\n",
    "# Format data:\n",
    "climind = climind.set_index([\"model\", \"year\", \"month\", \"index\"]).unstack(level=-1)[\"value\"]\n",
    "\n",
    "# Separate data by model, reset index and drop columns year and month:\n",
    "climind_FOCI = climind.loc[('FOCI')].reset_index().drop(columns=['year','month'])\n",
    "climind_CESM = climind.loc[('CESM')].reset_index().drop(columns=['year','month'])\n",
    "\n",
    "# Extract target series (PREC_SAHEL) and keep ALL indices (including PREC_SAHEL) as inputs:\n",
    "target_FOCI = climind_FOCI.loc[:, climind_FOCI.columns == 'PREC_SAHEL']\n",
    "target_CESM = climind_CESM.loc[:, climind_CESM.columns == 'PREC_SAHEL']\n",
    "input_FOCI = climind_FOCI.loc[:]\n",
    "input_CESM = climind_CESM.loc[:]\n",
    "\n",
    "# Normalize target series to have zero mean and unit variance:\n",
    "target_FOCI = (target_FOCI - np.mean(target_FOCI)) / np.std(target_FOCI)\n",
    "target_CESM = (target_CESM - np.mean(target_CESM)) / np.std(target_CESM)\n",
    "\n",
    "# Create targets with lead time 1, 3, 6 months:\n",
    "target_FOCI_lead1 = target_FOCI[1:-5].values\n",
    "target_FOCI_lead3 = target_FOCI[3:-3].values\n",
    "target_FOCI_lead6 = target_FOCI[6:].values\n",
    "target_CESM_lead1 = target_CESM[1:-5].values\n",
    "target_CESM_lead3 = target_CESM[3:-3].values\n",
    "target_CESM_lead6 = target_CESM[6:].values\n",
    "\n",
    "# Erase last 6 rows from inputs and target, to keep dimensions right:\n",
    "input_FOCI = input_FOCI[:-6]\n",
    "input_CESM = input_CESM[:-6]\n",
    "target_FOCI = target_FOCI[:-6]\n",
    "target_CESM = target_CESM[:-6]\n",
    "\n",
    "# Add targets with individual lead times as new columns:\n",
    "target_FOCI['PREC_SAHEL_lead1'] = target_FOCI_lead1\n",
    "target_FOCI['PREC_SAHEL_lead3'] = target_FOCI_lead3\n",
    "target_FOCI['PREC_SAHEL_lead6'] = target_FOCI_lead6\n",
    "target_CESM['PREC_SAHEL_lead1'] = target_CESM_lead1\n",
    "target_CESM['PREC_SAHEL_lead3'] = target_CESM_lead3\n",
    "target_CESM['PREC_SAHEL_lead6'] = target_CESM_lead6\n",
    "\n",
    "## Set parameters for inputs and target:\n",
    "\n",
    "# Select input features:\n",
    "input_features = [\n",
    "    'AMO', 'ENSO_12', 'ENSO_3', 'ENSO_34', 'ENSO_4', 'NAO_PC', 'NAO_ST', \n",
    "    'NP', 'PDO_PC', 'PREC_SAHEL', 'SAM_PC', 'SAM_ZM', 'SAT_N_ALL', 'SAT_N_LAND',\n",
    "    'SAT_N_OCEAN', 'SAT_S_ALL', 'SAT_S_LAND', 'SAT_S_OCEAN', 'SOI',\n",
    "    'SSS_ENA', 'SSS_NA', 'SSS_SA', 'SSS_WNA', 'SST_ESIO', 'SST_HMDR',\n",
    "    'SST_MED', 'SST_TNA', 'SST_TSA', 'SST_WSIO'\n",
    "]\n",
    "\n",
    "# Specify relative amount of train data:\n",
    "train_val_split = 0.9\n",
    "window_size = 12\n",
    "\n",
    "## Optionally choose to scale or normalize input features:\n",
    "# 'no': Keep raw input features.\n",
    "# 'scale_01': Scale input features with min/max scaling to [0,1].\n",
    "# 'scale_11': Scale input features with min/max scaling to [-1,1].\n",
    "# 'norm': Normalize input features, hence subtract mean and divide by std dev.\n",
    "scale_norm = 'norm'\n",
    "\n",
    "# Select specified input features:\n",
    "input_selected_FOCI = input_FOCI[input_features]\n",
    "input_selected_CESM = input_CESM[input_features]\n",
    "\n",
    "## Split inputs and targets into train and test sets:\n",
    "\n",
    "# Get number of train samples:\n",
    "n_train = int(train_val_split * len(input_selected_FOCI))\n",
    "\n",
    "# Split inputs and targets:\n",
    "train_input_FOCI = input_selected_FOCI[:n_train]\n",
    "train_input_CESM = input_selected_CESM[:n_train]\n",
    "test_input_FOCI = input_selected_FOCI[n_train - window_size:]\n",
    "test_input_CESM = input_selected_CESM[n_train - window_size:]\n",
    "\n",
    "train_target_FOCI = target_FOCI[:n_train]\n",
    "train_target_CESM = target_CESM[:n_train]\n",
    "test_target_FOCI = target_FOCI[n_train:]\n",
    "test_target_CESM = target_CESM[n_train:]\n",
    "\n",
    "# normalize the data\n",
    "scaler_FOCI = StandardScaler()\n",
    "scaler_CESM = StandardScaler()\n",
    "\n",
    "train_input_scaled_FOCI = scaler_FOCI.fit_transform(train_input_FOCI)\n",
    "test_input_scaled_FOCI = scaler_FOCI.transform(test_input_FOCI)\n",
    "train_input_scaled_CESM = scaler_CESM.fit_transform(train_input_CESM)\n",
    "test_input_scaled_CESM = scaler_CESM.transform(test_input_CESM)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DARTS models\n",
    "## Linear Regression lead time 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MSE for lead time 1 is: 0.9991140622468313\n"
     ]
    }
   ],
   "source": [
    "# Tryout models\n",
    "from darts.models import LinearRegressionModel\n",
    "from darts import TimeSeries\n",
    "from darts.metrics.metrics import mse\n",
    "\n",
    "train_input_CESM_ts = TimeSeries.from_values(train_input_scaled_CESM)\n",
    "train_target_CESM_ts = TimeSeries.from_values(train_target_CESM['PREC_SAHEL_lead1'].values)\n",
    "test_input_CESM_ts = TimeSeries.from_times_and_values(values=test_input_scaled_CESM, times=pd.RangeIndex(10794-window_size, 11982))\n",
    "test_target_CESM_ts = TimeSeries.from_times_and_values(values=test_target_CESM['PREC_SAHEL_lead1'].values, times=pd.RangeIndex(10794, 11982))\n",
    "\n",
    "naive_model = LinearRegressionModel(lags_past_covariates=window_size)\n",
    "naive_model.fit(series=train_target_CESM_ts, past_covariates=train_input_CESM_ts)\n",
    "\n",
    "predictions = naive_model.predict(1188, past_covariates=test_input_CESM_ts)\n",
    "\n",
    "mse_lead1 = mse(actual_series=test_target_CESM_ts, pred_series=predictions)\n",
    "print(f\"The MSE for lead time 1 is: {mse_lead1}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression lead time 3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MSE for lead time 3 is: 1.0328763529151652\n"
     ]
    }
   ],
   "source": [
    "train_input_CESM_ts = TimeSeries.from_values(train_input_scaled_CESM)\n",
    "train_target_CESM_ts = TimeSeries.from_values(train_target_CESM['PREC_SAHEL_lead3'].values)\n",
    "test_input_CESM_ts = TimeSeries.from_times_and_values(values=test_input_scaled_CESM, times=pd.RangeIndex(10794-window_size, 11982))\n",
    "test_target_CESM_ts = TimeSeries.from_times_and_values(values=test_target_CESM['PREC_SAHEL_lead3'].values, times=pd.RangeIndex(10794, 11982))\n",
    "\n",
    "naive_model = LinearRegressionModel(lags_past_covariates=window_size)\n",
    "naive_model.fit(series=train_target_CESM_ts, past_covariates=train_input_CESM_ts)\n",
    "\n",
    "predictions = naive_model.predict(1188, past_covariates=test_input_CESM_ts)\n",
    "\n",
    "mse_lead3 = mse(actual_series=test_target_CESM_ts, pred_series=predictions)\n",
    "print(f\"The MSE for lead time 3 is: {mse_lead3}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression lead time 6:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MSE for lead time 6 is: 1.0535867615718735\n"
     ]
    }
   ],
   "source": [
    "train_input_CESM_ts = TimeSeries.from_values(train_input_scaled_CESM)\n",
    "train_target_CESM_ts = TimeSeries.from_values(train_target_CESM['PREC_SAHEL_lead6'].values)\n",
    "test_input_CESM_ts = TimeSeries.from_times_and_values(values=test_input_scaled_CESM, times=pd.RangeIndex(10794-window_size, 11982))\n",
    "test_target_CESM_ts = TimeSeries.from_times_and_values(values=test_target_CESM['PREC_SAHEL_lead6'].values, times=pd.RangeIndex(10794, 11982))\n",
    "\n",
    "naive_model = LinearRegressionModel(lags_past_covariates=window_size)\n",
    "naive_model.fit(series=train_target_CESM_ts, past_covariates=train_input_CESM_ts)\n",
    "\n",
    "predictions = naive_model.predict(1188, past_covariates=test_input_CESM_ts)\n",
    "\n",
    "mse_lead6 = mse(actual_series=test_target_CESM_ts, pred_series=predictions)\n",
    "print(f\"The MSE for lead time 6 is: {mse_lead6}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XG Boost model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MSE for lead time 1 is: 1.0972040109315113\n"
     ]
    }
   ],
   "source": [
    "from darts.models.forecasting.xgboost import XGBModel\n",
    "\n",
    "train_input_CESM_ts = TimeSeries.from_values(train_input_scaled_CESM)\n",
    "train_target_CESM_ts = TimeSeries.from_values(train_target_CESM['PREC_SAHEL_lead1'].values)\n",
    "test_input_CESM_ts = TimeSeries.from_times_and_values(values=test_input_scaled_CESM, times=pd.RangeIndex(10794-window_size, 11982))\n",
    "test_target_CESM_ts = TimeSeries.from_times_and_values(values=test_target_CESM['PREC_SAHEL_lead1'].values, times=pd.RangeIndex(10794, 11982))\n",
    "\n",
    "\n",
    "model_xgb = XGBModel(lags_past_covariates=window_size, output_chunk_length=1)\n",
    "model_xgb.fit(series=train_target_CESM_ts, past_covariates=train_input_CESM_ts)\n",
    "\n",
    "predictions = model_xgb.predict(1188, past_covariates=test_input_CESM_ts)\n",
    "\n",
    "mse_lead1 = mse(actual_series=test_target_CESM_ts, pred_series=predictions)\n",
    "print(f\"The MSE for lead time 1 is: {mse_lead1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3070 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name          | Type             | Params\n",
      "---------------------------------------------------\n",
      "0 | criterion     | MSELoss          | 0     \n",
      "1 | train_metrics | MetricCollection | 0     \n",
      "2 | val_metrics   | MetricCollection | 0     \n",
      "3 | rnn           | LSTM             | 25.1 K\n",
      "4 | fc            | Sequential       | 33    \n",
      "---------------------------------------------------\n",
      "25.1 K    Trainable params\n",
      "0         Non-trainable params\n",
      "25.1 K    Total params\n",
      "0.100     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 337/337 [00:02<00:00, 133.74it/s, v_num=logs, train_loss=0.520, val_loss=0.946]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3070 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00,  1.88it/s]\n",
      "The MSE for lead time 1 is: 0.9477404867715031\n"
     ]
    }
   ],
   "source": [
    "from darts.models.forecasting.block_rnn_model import BlockRNNModel\n",
    "\n",
    "train_input_CESM_ts = TimeSeries.from_values(train_input_scaled_CESM)\n",
    "train_target_CESM_ts = TimeSeries.from_values(\n",
    "    train_target_CESM[\"PREC_SAHEL_lead1\"].values\n",
    ")\n",
    "test_input_CESM_ts = TimeSeries.from_times_and_values(\n",
    "    values=test_input_scaled_CESM, times=pd.RangeIndex(10794 - window_size, 11982)\n",
    ")\n",
    "test_target_CESM_ts = TimeSeries.from_times_and_values(\n",
    "    values=test_target_CESM[\"PREC_SAHEL_lead1\"].values,\n",
    "    times=pd.RangeIndex(10794, 11982),\n",
    ")\n",
    "\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "\n",
    "# stop training when validation loss does not decrease more than 0.05 (`min_delta`) over\n",
    "# a period of 5 epochs (`patience`)\n",
    "my_stopper = EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    patience=5,\n",
    "    min_delta=0.05,\n",
    "    mode='min',\n",
    ")\n",
    "\n",
    "pl_trainer_kwargs={\"callbacks\": [my_stopper]}\n",
    "\n",
    "model_RNN = BlockRNNModel(\n",
    "    input_chunk_length=window_size,\n",
    "    output_chunk_length=1,\n",
    "    model=\"LSTM\",\n",
    "    hidden_dim=32,\n",
    "    n_rnn_layers=3,\n",
    "    dropout=0.3,\n",
    "    pl_trainer_kwargs=pl_trainer_kwargs,\n",
    "    log_tensorboard=True,\n",
    "\n",
    ")\n",
    "\n",
    "model_RNN.fit(series=train_target_CESM_ts, past_covariates=train_input_CESM_ts, val_series=test_target_CESM_ts, val_past_covariates=test_input_CESM_ts)\n",
    "\n",
    "predictions = model_RNN.predict(1188, past_covariates=test_input_CESM_ts)\n",
    "\n",
    "mse_lead1 = mse(actual_series=test_target_CESM_ts, pred_series=predictions)\n",
    "print(f\"The MSE for lead time 1 is: {mse_lead1}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3070 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name          | Type             | Params\n",
      "---------------------------------------------------\n",
      "0 | criterion     | MSELoss          | 0     \n",
      "1 | train_metrics | MetricCollection | 0     \n",
      "2 | val_metrics   | MetricCollection | 0     \n",
      "3 | rnn           | LSTM             | 91.1 K\n",
      "4 | fc            | Sequential       | 65    \n",
      "---------------------------------------------------\n",
      "91.2 K    Trainable params\n",
      "0         Non-trainable params\n",
      "91.2 K    Total params\n",
      "0.365     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 337/337 [00:03<00:00, 106.44it/s, v_num=logs, train_loss=0.991, val_loss=0.967]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3070 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00,  1.61it/s]\n",
      "The MSE for lead time 1 is: 0.9629192905164679\n"
     ]
    }
   ],
   "source": [
    "from darts.models.forecasting.block_rnn_model import BlockRNNModel\n",
    "\n",
    "train_input_CESM_ts = TimeSeries.from_values(train_input_scaled_CESM)\n",
    "train_target_CESM_ts = TimeSeries.from_values(\n",
    "    train_target_CESM[\"PREC_SAHEL_lead1\"].values\n",
    ")\n",
    "test_input_CESM_ts = TimeSeries.from_times_and_values(\n",
    "    values=test_input_scaled_CESM, times=pd.RangeIndex(10794 - window_size, 11982)\n",
    ")\n",
    "test_target_CESM_ts = TimeSeries.from_times_and_values(\n",
    "    values=test_target_CESM[\"PREC_SAHEL_lead1\"].values,\n",
    "    times=pd.RangeIndex(10794, 11982),\n",
    ")\n",
    "\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "\n",
    "# stop training when validation loss does not decrease more than 0.05 (`min_delta`) over\n",
    "# a period of 5 epochs (`patience`)\n",
    "my_stopper = EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    patience=5,\n",
    "    min_delta=0.01,\n",
    "    mode='min',\n",
    ")\n",
    "\n",
    "pl_trainer_kwargs={\"callbacks\": [my_stopper]}\n",
    "\n",
    "model_RNN = BlockRNNModel(\n",
    "    input_chunk_length=window_size,\n",
    "    output_chunk_length=1,\n",
    "    model=\"LSTM\",\n",
    "    hidden_dim=64,\n",
    "    n_rnn_layers=3,\n",
    "    dropout=0.3,\n",
    "    pl_trainer_kwargs=pl_trainer_kwargs,\n",
    "    log_tensorboard=True,\n",
    "\n",
    ")\n",
    "\n",
    "model_RNN.fit(series=train_target_CESM_ts, past_covariates=train_input_CESM_ts, val_series=test_target_CESM_ts, val_past_covariates=test_input_CESM_ts)\n",
    "\n",
    "predictions = model_RNN.predict(1188, past_covariates=test_input_CESM_ts)\n",
    "\n",
    "mse_lead1 = mse(actual_series=test_target_CESM_ts, pred_series=predictions)\n",
    "print(f\"The MSE for lead time 1 is: {mse_lead1}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3070 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name                | Type                | Params\n",
      "------------------------------------------------------------\n",
      "0 | criterion           | MSELoss             | 0     \n",
      "1 | train_metrics       | MetricCollection    | 0     \n",
      "2 | val_metrics         | MetricCollection    | 0     \n",
      "3 | encoder             | Linear              | 2.0 K \n",
      "4 | positional_encoding | _PositionalEncoding | 0     \n",
      "5 | transformer         | Transformer         | 548 K \n",
      "6 | decoder             | Linear              | 65    \n",
      "------------------------------------------------------------\n",
      "550 K     Trainable params\n",
      "0         Non-trainable params\n",
      "550 K     Total params\n",
      "2.203     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10:  74%|███████▎  | 246/334 [00:13<00:04, 18.79it/s, v_num=logs, train_loss=0.378, val_loss=1.060]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jake/desktop/git/Sahel_Rainfall/.ve_Sahel_Rainfall/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py:54: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3070 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:01<00:00,  1.92s/it]\n",
      "The MSE for lead time 1 is: 1.0407771839207207\n"
     ]
    }
   ],
   "source": [
    "from darts.models.forecasting.transformer_model import TransformerModel\n",
    "\n",
    "train_input_CESM_ts = TimeSeries.from_values(train_input_scaled_CESM)\n",
    "train_target_CESM_ts = TimeSeries.from_values(\n",
    "    train_target_CESM[\"PREC_SAHEL_lead1\"].values\n",
    ")\n",
    "test_input_CESM_ts = TimeSeries.from_times_and_values(\n",
    "    values=test_input_scaled_CESM, times=pd.RangeIndex(10794 - window_size, 11982)\n",
    ")\n",
    "test_target_CESM_ts = TimeSeries.from_times_and_values(\n",
    "    values=test_target_CESM[\"PREC_SAHEL_lead1\"].values,\n",
    "    times=pd.RangeIndex(10794, 11982),\n",
    ")\n",
    "\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "\n",
    "# stop training when validation loss does not decrease more than 0.05 (`min_delta`) over\n",
    "# a period of 5 epochs (`patience`)\n",
    "my_stopper = EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    patience=7,\n",
    "    min_delta=0.01,\n",
    "    mode='min',\n",
    ")\n",
    "\n",
    "pl_trainer_kwargs={\"callbacks\": [my_stopper]}\n",
    "\n",
    "model_trans = TransformerModel(\n",
    "    input_chunk_length=window_size,\n",
    "    output_chunk_length=1,\n",
    "    dropout=0.3,\n",
    "    pl_trainer_kwargs=pl_trainer_kwargs,\n",
    "    log_tensorboard=True,\n",
    "\n",
    ")\n",
    "\n",
    "model_trans.fit(series=train_target_CESM_ts, past_covariates=train_input_CESM_ts, val_series=test_target_CESM_ts, val_past_covariates=test_input_CESM_ts)\n",
    "\n",
    "predictions = model_trans.predict(1188, past_covariates=test_input_CESM_ts)\n",
    "\n",
    "mse_lead1 = mse(actual_series=test_target_CESM_ts, pred_series=predictions)\n",
    "print(f\"The MSE for lead time 1 is: {mse_lead1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3070 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name          | Type             | Params\n",
      "---------------------------------------------------\n",
      "0 | criterion     | MSELoss          | 0     \n",
      "1 | train_metrics | MetricCollection | 0     \n",
      "2 | val_metrics   | MetricCollection | 0     \n",
      "3 | stacks        | ModuleList       | 34.3 M\n",
      "---------------------------------------------------\n",
      "34.3 M    Trainable params\n",
      "22.9 K    Non-trainable params\n",
      "34.3 M    Total params\n",
      "137.230   Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 334/334 [00:28<00:00, 11.60it/s, v_num=logs, train_loss=571.0, val_loss=1.09e+5]    \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3070 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:05<00:00,  5.39s/it]\n",
      "The MSE for lead time 1 is: 22.32790993366191\n"
     ]
    }
   ],
   "source": [
    "from darts.models.forecasting.nbeats import NBEATSModel\n",
    "\n",
    "train_input_CESM_ts = TimeSeries.from_values(train_input_scaled_CESM)\n",
    "train_target_CESM_ts = TimeSeries.from_values(\n",
    "    train_target_CESM[\"PREC_SAHEL_lead1\"].values\n",
    ")\n",
    "test_input_CESM_ts = TimeSeries.from_times_and_values(\n",
    "    values=test_input_scaled_CESM, times=pd.RangeIndex(10794 - window_size, 11982)\n",
    ")\n",
    "test_target_CESM_ts = TimeSeries.from_times_and_values(\n",
    "    values=test_target_CESM[\"PREC_SAHEL_lead1\"].values,\n",
    "    times=pd.RangeIndex(10794, 11982),\n",
    ")\n",
    "\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "\n",
    "# stop training when validation loss does not decrease more than 0.05 (`min_delta`) over\n",
    "# a period of 5 epochs (`patience`)\n",
    "my_stopper = EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    patience=7,\n",
    "    min_delta=0.01,\n",
    "    mode='min',\n",
    ")\n",
    "\n",
    "pl_trainer_kwargs={\"callbacks\": [my_stopper]}\n",
    "\n",
    "model_nbeats = NBEATSModel(\n",
    "    input_chunk_length=window_size,\n",
    "    output_chunk_length=1,\n",
    "    dropout=0.3,\n",
    "    pl_trainer_kwargs=pl_trainer_kwargs,\n",
    "    log_tensorboard=True,\n",
    "\n",
    ")\n",
    "\n",
    "model_nbeats.fit(series=train_target_CESM_ts, past_covariates=train_input_CESM_ts, val_series=test_target_CESM_ts, val_past_covariates=test_input_CESM_ts)\n",
    "\n",
    "predictions = model_nbeats.predict(1188, past_covariates=test_input_CESM_ts)\n",
    "\n",
    "mse_lead1 = mse(actual_series=test_target_CESM_ts, pred_series=predictions)\n",
    "print(f\"The MSE for lead time 1 is: {mse_lead1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3070 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name                              | Type                             | Params\n",
      "----------------------------------------------------------------------------------------\n",
      "0  | train_metrics                     | MetricCollection                 | 0     \n",
      "1  | val_metrics                       | MetricCollection                 | 0     \n",
      "2  | input_embeddings                  | _MultiEmbedding                  | 0     \n",
      "3  | static_covariates_vsn             | _VariableSelectionNetwork        | 0     \n",
      "4  | encoder_vsn                       | _VariableSelectionNetwork        | 22.1 K\n",
      "5  | decoder_vsn                       | _VariableSelectionNetwork        | 528   \n",
      "6  | static_context_grn                | _GatedResidualNetwork            | 1.1 K \n",
      "7  | static_context_hidden_encoder_grn | _GatedResidualNetwork            | 1.1 K \n",
      "8  | static_context_cell_encoder_grn   | _GatedResidualNetwork            | 1.1 K \n",
      "9  | static_context_enrichment         | _GatedResidualNetwork            | 1.1 K \n",
      "10 | lstm_encoder                      | LSTM                             | 2.2 K \n",
      "11 | lstm_decoder                      | LSTM                             | 2.2 K \n",
      "12 | post_lstm_gan                     | _GateAddNorm                     | 576   \n",
      "13 | static_enrichment_grn             | _GatedResidualNetwork            | 1.4 K \n",
      "14 | multihead_attn                    | _InterpretableMultiHeadAttention | 676   \n",
      "15 | post_attn_gan                     | _GateAddNorm                     | 576   \n",
      "16 | feed_forward_block                | _GatedResidualNetwork            | 1.1 K \n",
      "17 | pre_output_gan                    | _GateAddNorm                     | 576   \n",
      "18 | output_layer                      | Linear                           | 289   \n",
      "----------------------------------------------------------------------------------------\n",
      "36.6 K    Trainable params\n",
      "0         Non-trainable params\n",
      "36.6 K    Total params\n",
      "0.146     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21: 100%|██████████| 337/337 [00:12<00:00, 26.38it/s, v_num=logs, train_loss=2.610, val_loss=3.190]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3070 Ti') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:07<00:00,  7.96s/it]\n",
      "The MSE for lead time 1 is: 1.7924541733682364\n"
     ]
    }
   ],
   "source": [
    "from darts.models.forecasting.tft_model import TFTModel\n",
    "\n",
    "train_input_CESM_ts = TimeSeries.from_values(train_input_scaled_CESM)\n",
    "train_target_CESM_ts = TimeSeries.from_values(\n",
    "    train_target_CESM[\"PREC_SAHEL_lead1\"].values\n",
    ")\n",
    "test_input_CESM_ts = TimeSeries.from_times_and_values(\n",
    "    values=test_input_scaled_CESM, times=pd.RangeIndex(10794 - window_size, 11982)\n",
    ")\n",
    "test_target_CESM_ts = TimeSeries.from_times_and_values(\n",
    "    values=test_target_CESM[\"PREC_SAHEL_lead1\"].values,\n",
    "    times=pd.RangeIndex(10794, 11982),\n",
    ")\n",
    "\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "\n",
    "# stop training when validation loss does not decrease more than 0.05 (`min_delta`) over\n",
    "# a period of 5 epochs (`patience`)\n",
    "my_stopper = EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    patience=5,\n",
    "    min_delta=0.01,\n",
    "    mode='min',\n",
    ")\n",
    "\n",
    "pl_trainer_kwargs={\"callbacks\": [my_stopper]}\n",
    "\n",
    "model_tft = TFTModel(\n",
    "    input_chunk_length=window_size,\n",
    "    output_chunk_length=1,\n",
    "    dropout=0.3,\n",
    "    pl_trainer_kwargs=pl_trainer_kwargs,\n",
    "    log_tensorboard=True,\n",
    "    add_relative_index=True\n",
    "\n",
    ")\n",
    "\n",
    "model_tft.fit(series=train_target_CESM_ts, past_covariates=train_input_CESM_ts, val_series=test_target_CESM_ts, val_past_covariates=test_input_CESM_ts)\n",
    "\n",
    "predictions = model_tft.predict(1188, past_covariates=test_input_CESM_ts)\n",
    "\n",
    "mse_lead1 = mse(actual_series=test_target_CESM_ts, pred_series=predictions)\n",
    "print(f\"The MSE for lead time 1 is: {mse_lead1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".ve_Sahel_Rainfall",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
